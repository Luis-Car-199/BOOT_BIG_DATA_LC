Ejercicios comentados:

En el ejercicio 1:

Creamos un cluster hadoop desde google cloud data proc. Esto lo hago para tener un entorno distribuido y poder ejecutar trabajos hadoop como el procesamiento de grandes volumenes datos.
Por otro lado creo un bucket para hacer una prueba de descarga desde google cloud al sistema de archivos del cluster hadoop. Primero subo los jar de configuracion al bucket y despues desde la consola de del nodo maestro del cluster descargo los archivos que hay en el bucket.

Ejercicio 2:

Ejercicio 3:

Lo que hemos hecho aqui es configurar en el cluster hadoop Hive para poder hacer consultas y analisis de los datos almacenados en HDFS

